{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ec3252-3e18-4abc-b3cf-83c18ce5cba0",
   "metadata": {},
   "source": [
    "# Training U-Net\n",
    "\n",
    "Training a U-Net for denoising LP STEM images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681d1d8-3d48-42eb-a4ae-c8a5456381ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "### Enter the location of your aquaDenoising folder containing the general_functions folder\n",
    "sys.path.append(\"path/to/aquaDenoising/\")\n",
    "\n",
    "from general_functions.neural_networks.norm_patch import robustnorm, randompatch\n",
    "from general_functions.neural_networks.architectures import model_unet\n",
    "from general_functions.neural_networks.metrics import ssimsmape_loss, ssim, psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e281e0b-ed91-450e-a57f-38ccc0820538",
   "metadata": {},
   "source": [
    "## Load Simulated Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d163f-add3-4523-bd37-b3c04bc7157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_PATCH = 512\n",
    "PATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02f9cb-d434-4cd8-8e10-1d71fbc6ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "allshape_clean = np.load(\"simulated/noiseless/images/dataset\")\n",
    "allshape_SNR = np.load(\"simulated/noisy/images/dataset\")\n",
    "\n",
    "allshape_clean = np.expand_dims(allshape_clean, axis=3)\n",
    "allshape_SNR = np.expand_dims(allshape_SNR, axis=3)\n",
    "\n",
    "allshape_clean.shape, allshape_SNR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fdb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(9, 5, figsize=[20, 36])\n",
    "# for i in range(9):\n",
    "#     for ii in range(5):\n",
    "#         ax[i,ii].imshow(allshape_clean[ii*9+i])\n",
    "#         ax[i,ii].set_title(f\"{ii*9+i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train - Validation Split\n",
    "# %%time\n",
    "\n",
    "training_full_img_in = allshape_SNR[:-9]\n",
    "training_full_img_out = allshape_clean[:-9]\n",
    "\n",
    "validation_full_img_in = allshape_SNR[-9:]\n",
    "validation_full_img_out = allshape_clean[-9:]\n",
    "\n",
    "training_full_img_in.shape, validation_full_img_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537d8f4-f44e-485a-9c32-971a8bf50a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "train_seed = 813\n",
    "\n",
    "train_input  = np.zeros((0, PATCH_SIZE, PATCH_SIZE))\n",
    "train_output = np.zeros((0, PATCH_SIZE, PATCH_SIZE))\n",
    "\n",
    "for idx in range(training_full_img_in.shape[0]):\n",
    "    train_input = np.append(train_input, randompatch(training_full_img_in[idx], NB_PATCH, patch_size=PATCH_SIZE, seed=train_seed, write_xy=False), axis=0)    \n",
    "    train_output = np.append(train_output, randompatch(training_full_img_out[idx], NB_PATCH, patch_size=PATCH_SIZE, seed=train_seed, write_xy=False), axis=0)\n",
    "    \n",
    "train_input = robustnorm(train_input, 0.01)\n",
    "train_output = robustnorm(train_output, 0)\n",
    "    \n",
    "train_input  = np.expand_dims(train_input, axis=3)\n",
    "train_output = np.expand_dims(train_output, axis=3)\n",
    "\n",
    "train_input.shape, train_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbb2ec-5b79-4788-adc3-662199c26c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "val_seed = 525\n",
    "\n",
    "val_input  = np.zeros((0,PATCH_SIZE,PATCH_SIZE))\n",
    "val_output = np.zeros((0,PATCH_SIZE,PATCH_SIZE))\n",
    "\n",
    "for idx in range(validation_full_img_in.shape[0]):\n",
    "    val_input = np.append(val_input, randompatch(validation_full_img_in[idx], NB_PATCH, patch_size=PATCH_SIZE, seed=val_seed, write_xy=False), axis=0)\n",
    "    val_output = np.append(val_output,randompatch(validation_full_img_out[idx], NB_PATCH, patch_size=PATCH_SIZE, seed=val_seed, write_xy=False), axis=0)\n",
    "\n",
    "val_input = robustnorm(val_input, 0.01)\n",
    "val_output = robustnorm(val_output, 0)\n",
    "    \n",
    "val_input  = np.expand_dims(val_input, axis=3)\n",
    "val_output = np.expand_dims(val_output, axis=3)\n",
    "\n",
    "val_input.shape, val_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425bb7c-9a90-4c12-b7fd-e2b483977e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,5,figsize=(24,12))\n",
    "\n",
    "patch_img = 2804\n",
    "ax[0,0].imshow(train_input[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[1,0].imshow(train_output[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[0,0].set_title(f\"min:{np.min(train_input[patch_img,:,:,0])} max:{np.max(train_input[patch_img,:,:,0])}\")\n",
    "\n",
    "patch_img = 351\n",
    "ax[0,1].imshow(train_input[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[1,1].imshow(train_output[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[0,1].set_title(f\"min:{np.min(train_input[patch_img,:,:,0])} max:{np.max(train_input[patch_img,:,:,0])}\")\n",
    "\n",
    "patch_img = 1461\n",
    "ax[0,2].imshow(train_input[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[1,2].imshow(train_output[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[0,2].set_title(f\"min:{np.min(train_input[patch_img,:,:,0])} max:{np.max(train_input[patch_img,:,:,0])}\")\n",
    "\n",
    "patch_img = 1593\n",
    "ax[0,3].imshow(train_input[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[1,3].imshow(train_output[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[0,3].set_title(f\"min:{np.min(train_input[patch_img,:,:,0])} max:{np.max(train_input[patch_img,:,:,0])}\")\n",
    "\n",
    "patch_img = 872\n",
    "ax[0,4].imshow(train_input[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[1,4].imshow(train_output[patch_img,:,:,0], cmap=\"gray\")\n",
    "ax[0,4].set_title(f\"min:{np.min(train_input[patch_img,:,:,0])} max:{np.max(train_input[patch_img,:,:,0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e932a-788d-48ed-913a-9cfcf82f5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Parameters\n",
    "\n",
    "TRAINING_NB = \"01\"\n",
    "\n",
    "NUM_EPOCHS = 300\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "### - - - - - - - - - -\n",
    "\n",
    "input_img = Input((128, 128, 1), name='img')\n",
    "save_dir = f\"DATA/UNet/saved_models/Training{TRAINING_NB}/\"\n",
    "\n",
    "model = model_unet(input_img, 1, n_filters=8, layers_repetition=2, dropout=0.05)\n",
    "loss = {\"output_denoised\":ssimsmape_loss}\n",
    "model.compile(optimizer=Adam(),loss=loss, metrics= [\"accuracy\", ssim, psnr, 'mean_absolute_percentage_error'])\n",
    "\n",
    "### Callbacks\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_dir+f\"model_vloss_min.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor = 'val_loss',\n",
    "                                       patience=15,\n",
    "                                       verbose=1,\n",
    "                                       mode='min')\n",
    "                                       # restore_best_weights = True\n",
    "\n",
    "Reduce_LR = ReduceLROnPlateau(factor=0.1,\n",
    "                              patience=5,\n",
    "                              min_lr=0.00001,\n",
    "                              verbose=1)\n",
    "\n",
    "Model_checkpoint = ModelCheckpoint(filepath = save_dir+f\"model.h5\",\n",
    "                                   verbose=1,\n",
    "                                   save_best_only = False)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping_monitor, Reduce_LR, Model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f08838-1d4b-4878-aef9-ce29872422ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_input, train_output, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=callbacks_list,\n",
    "                    validation_data=(val_input, val_output), use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7dced-6efc-40d8-858f-16808a0a6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=[8,6])\n",
    "ax.plot(history.epoch[1:], history.history[\"loss\"][1:], \".-\", label=\"Training\")\n",
    "ax.set_ylabel(\"Loss : ssimSMAPE\", fontsize=20)\n",
    "ax.plot(history.epoch[1:], history.history[\"val_loss\"][1:], \".-\", label=\"Validation\")    \n",
    "ax.set_xlim(0,75)\n",
    "ax.set_xlabel(\"Epochs\", fontsize=20)\n",
    "ax.set_title(\"Loss function\", fontsize=25)\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "fig.savefig(f\"DATA/UNet/saved_models/Training{TRAINING_NB}/Training_Curve.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647605fa-8276-4cd9-a565-08622b3eb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f\"DATA/UNet/saved_models/Training{TRAINING_NB}/model_vloss_min.h5\")\n",
    "\n",
    "metrics = model.evaluate(val_input, val_output)\n",
    "metrics_dict = dict(zip(model.metrics_names, metrics))\n",
    "\n",
    "print(\"\\n\")\n",
    "# print(\"The scores of the metrics of the model '\" + model_folder.split(\"/\")[-1] + \"' are:\")\n",
    "print(metrics_dict)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f3093-effc-4cd2-957d-24e786393eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add entries to the dictionnary to match the characteristics of the training\n",
    "\n",
    "metrics_dict[\"training\"] = f\"Training{TRAINING_NB}\"\n",
    "# metrics_dict[\"dataset_size\"] = training_size\n",
    "\n",
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "# print(\"The scores of the metrics of the model '\" + model_folder.split(\"/\")[-1] + \"' are:\")\n",
    "print(metrics_dict)\n",
    "print(\"\\n\")\n",
    "\n",
    "### Choose to file location where all the results are saved\n",
    "\n",
    "allscores_file = \"DATA/UNet/saved_models/compare_scores.csv\"\n",
    "\n",
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_dict, index=[0])\n",
    "\n",
    "try:\n",
    "    allscores_df = pd.read_csv(allscores_file)\n",
    "    allscores_df = pd.concat([allscores_df, metrics_df], ignore_index=True)\n",
    "    allscores_df.to_csv(allscores_file, index=False)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    metrics_df.to_csv(allscores_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
